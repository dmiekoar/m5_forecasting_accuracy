{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings, gc, sys, json\n",
    "import datetime as dt\n",
    "from m5_utils import *\n",
    "\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#import tsfresh\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.decomposition import PCA, FastICA, TruncatedSVD\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input/dict_m5.json') as json_file:\n",
    "    dict_m5 = json.load(json_file)\n",
    "with open('input/dict_m5_inv.json') as json_file:\n",
    "    dict_m5_inv = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holidays feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv('input/calendar.csv')\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = pd.read_csv('input/holidays_consolidated.csv')\n",
    "holidays['date'] = pd.to_datetime(holidays['Holiday_Date'])\n",
    "del holidays['Holiday_Date']\n",
    "holidays.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# All calendar are exactly the same. Keeping and checking only one then\n",
    "\n",
    "holidays.drop_duplicates(['Holiday_Description','date','state'], keep='first', inplace= True)\n",
    "check1 = holidays.groupby( ['Holiday_Description','date'])['date'].count()\n",
    "check1.reset_index(drop = True).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.drop_duplicates(['Holiday_Description','date'], keep='first', inplace= True)\n",
    "holidays.drop(['state'], axis = 1, inplace = True)\n",
    "holidays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge holidays with calendar\n",
    "calendar = calendar.merge(holidays, how = 'left', on = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are four dates which werent covered by the calendar.\n",
    "calendar[(calendar['Holiday_Description'].isna()==False)&(calendar['event_type_1'].isna()==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del weather['state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6576, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>totalSnow_cm</th>\n",
       "      <th>FeelsLikeC</th>\n",
       "      <th>HeatIndexC</th>\n",
       "      <th>WindChillC</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>tempC</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>-1.40000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.40000</td>\n",
       "      <td>49.60000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-10</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-11</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.20000</td>\n",
       "      <td>3.60000</td>\n",
       "      <td>2.20000</td>\n",
       "      <td>43.10000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.60000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-12</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.20000</td>\n",
       "      <td>5.90000</td>\n",
       "      <td>5.20000</td>\n",
       "      <td>48.30000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.90000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.70000</td>\n",
       "      <td>9.70000</td>\n",
       "      <td>8.70000</td>\n",
       "      <td>60.70000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  totalSnow_cm  FeelsLikeC  HeatIndexC  WindChillC  humidity  \\\n",
       "0  2011-01-01       0.30000    -1.40000     1.00000    -1.40000  49.60000   \n",
       "1  2011-01-10       0.00000     0.10000     2.50000     0.10000  55.00000   \n",
       "2  2011-01-11       0.00000     2.20000     3.60000     2.20000  43.10000   \n",
       "3  2011-01-12       0.00000     5.20000     5.90000     5.20000  48.30000   \n",
       "4  2011-01-13       0.00000     8.70000     9.70000     8.70000  60.70000   \n",
       "\n",
       "   precipMM   tempC  state_id  \n",
       "0   0.00000 1.00000         0  \n",
       "1   0.00000 2.50000         0  \n",
       "2   0.00000 3.60000         0  \n",
       "3   0.00000 5.90000         0  \n",
       "4   0.00000 9.70000         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.14 Mb (68.0% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date             object\n",
       "totalSnow_cm    float16\n",
       "FeelsLikeC      float16\n",
       "HeatIndexC      float16\n",
       "WindChillC      float16\n",
       "humidity        float16\n",
       "precipMM        float16\n",
       "tempC           float16\n",
       "state_id           int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv('input/weather_consolidated.csv')\n",
    "print(weather.shape); weather.head()\n",
    "weather = reduce_mem_usage(weather)\n",
    "weather.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_features(df):\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['weekend'] = (df['wday'] <3).astype(int)\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['week'] = df['date'].dt.week\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    df['weekofyear'] = df['date'].dt.weekofyear\n",
    "    \n",
    "    return df\n",
    "    # Add holidays \n",
    "    #add_holidays(df)\n",
    "\n",
    "def add_holidays(df):\n",
    "    \n",
    "    #df['natal_2017'] = (pd.to_datetime('2017-12-25') - df['purchase_date']).dt.days.apply(lambda x: (1-x/37) if x > -7 and x < 30 else 0)\n",
    "     print('no additional holidays so far')\n",
    "\n",
    "def add_weather(df, weather):\n",
    "    \n",
    "    df = df.merge(weather, how='left', on=['date','state_id'])\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def simple_fe(data):\n",
    "    \n",
    "    # demand features\n",
    "    data['lag_t28'] = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28))\n",
    "    data['lag_t29'] = data.groupby(['id'])['demand'].transform(lambda x: x.shift(29))\n",
    "    data['lag_t30'] = data.groupby(['id'])['demand'].transform(lambda x: x.shift(30))\n",
    "    data['lag_t31'] = data.groupby(['id'])['demand'].transform(lambda x: x.shift(31))\n",
    "    \n",
    "    data['rolling_mean_t7']   = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).mean())\n",
    "    data['rolling_std_t7']    = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).std())\n",
    "    \n",
    "    data['rolling_mean_t30']  = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).mean())\n",
    "    data['rolling_std_t30']   = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).std())\n",
    "    \n",
    "    data['rolling_mean_t90']  = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(90).mean())\n",
    "    data['rolling_std_t90']   = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(90).std())\n",
    "    \n",
    "    data['rolling_mean_t180'] = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(180).mean())\n",
    "    data['rolling_std_t180']  = data.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(180).std())\n",
    "    \n",
    "    # price features\n",
    "    data['lag_price_t1']           = data.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1))\n",
    "    data['price_change_t1']        = (data['lag_price_t1'] - data['sell_price']) / (data['lag_price_t1'])\n",
    "    data['rolling_price_max_t365'] = data.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1).rolling(365).max())\n",
    "    data['price_change_t365']      = (data['rolling_price_max_t365'] - data['sell_price']) / (data['rolling_price_max_t365'])\n",
    "    data.drop(['rolling_price_max_t365', 'lag_price_t1'], inplace = True, axis = 1)\n",
    "    \n",
    "    data['rolling_price_std_t7']   = data.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(7).std())\n",
    "    data['rolling_price_std_t30']  = data.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(30).std())\n",
    "    data['rolling_price_std_t90']  = data.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(90).std())\n",
    "    data['rolling_price_std_t180'] = data.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(180).std())\n",
    "    \n",
    "    # time features\n",
    "    add_datetime_features(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def _kurtosis(x):\n",
    "    return kurtosis(x)\n",
    "\n",
    "\n",
    "def CPT5(x):\n",
    "    den = len(x)*np.exp(np.std(x))\n",
    "    return sum(np.exp(x))/den\n",
    "\n",
    "def skewness(x):\n",
    "    return skew(x)\n",
    "\n",
    "def SSC(x):\n",
    "    x = np.array(x)\n",
    "    x = np.append(x[-1], x)\n",
    "    x = np.append(x,x[1])\n",
    "    xn = x[1:len(x)-1]\n",
    "    xn_i2 = x[2:len(x)]    # xn+1 \n",
    "    xn_i1 = x[0:len(x)-2]  # xn-1\n",
    "    ans = np.heaviside((xn-xn_i1)*(xn-xn_i2),0)\n",
    "    return sum(ans[1:]) \n",
    "\n",
    "def wave_length(x):\n",
    "    x = np.array(x)\n",
    "    x = np.append(x[-1], x)\n",
    "    x = np.append(x,x[1])\n",
    "    xn = x[1:len(x)-1]\n",
    "    xn_i2 = x[2:len(x)]    # xn+1 \n",
    "    return sum(abs(xn_i2-xn))\n",
    "    \n",
    "def norm_entropy(x):\n",
    "    tresh = 3\n",
    "    return sum(np.power(abs(x),tresh))\n",
    "\n",
    "def SRAV(x):    \n",
    "    SRA = sum(np.sqrt(abs(x)))\n",
    "    return np.power(SRA/len(x),2)\n",
    "\n",
    "def mean_abs(x):\n",
    "    return sum(abs(x))/len(x)\n",
    "\n",
    "def zero_crossing(x):\n",
    "    x = np.array(x)\n",
    "    x = np.append(x[-1], x)\n",
    "    x = np.append(x,x[1])\n",
    "    xn = x[1:len(x)-1]\n",
    "    xn_i2 = x[2:len(x)]    # xn+1\n",
    "    return sum(np.heaviside(-xn*xn_i2,0))\n",
    "\n",
    "# Funcao para criar alguns features estatisticas avancadas\n",
    "def advanced_fe(data):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    def mean_change_of_abs_change(x):\n",
    "        return np.mean(np.diff(np.abs(np.diff(x))))\n",
    "    \n",
    "    for col in data.columns:\n",
    "        \n",
    "        print('col 1: ',col)\n",
    "        if col in ['demand','sell_price']:\n",
    "            \n",
    "            df[col + '_mean'] = data.groupby(['id'])[col].mean()\n",
    "            df[col + '_median'] = data.groupby(['id'])[col].median()\n",
    "            df[col + '_max'] = data.groupby(['id'])[col].max()\n",
    "            df[col + '_min'] = data.groupby(['id'])[col].min()\n",
    "            df[col + '_std'] = data.groupby(['id'])[col].std()\n",
    "            df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n",
    "            df[col + '_maxtoMin'] = df[col + '_max'] / df[col + '_min']\n",
    "            df[col + '_mean_abs_chg'] = data.groupby(['id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "            df[col + '_mean_change_of_abs_change'] = data.groupby('id')[col].apply(mean_change_of_abs_change)\n",
    "            df[col + '_abs_max'] = data.groupby(['id'])[col].apply(lambda x: np.max(np.abs(x)))\n",
    "            df[col + '_abs_min'] = data.groupby(['id'])[col].apply(lambda x: np.min(np.abs(x)))\n",
    "            df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])/2\n",
    "            \n",
    "            print('col 2: ',col)\n",
    "            \n",
    "            # Advanced Features\n",
    "            df[col + '_skew'] = data.groupby(['id'])[col].skew()\n",
    "            df[col + '_mad'] = data.groupby(['id'])[col].mad()\n",
    "            df[col + '_q25'] = data.groupby(['id'])[col].quantile(0.25)\n",
    "            df[col + '_q75'] = data.groupby(['id'])[col].quantile(0.75)\n",
    "            df[col + '_q95'] = data.groupby(['id'])[col].quantile(0.95)\n",
    "            df[col + '_iqr'] = df[col + '_q75'] - df[col + '_q25']\n",
    "            df[col + '_SSC'] = data.groupby(['id'])[col].apply(SSC) \n",
    "            df[col + '_skewness'] = data.groupby(['id'])[col].apply(skewness)\n",
    "            df[col + '_wave_lenght'] = data.groupby(['id'])[col].apply(wave_length)\n",
    "            df[col + '_norm_entropy'] = data.groupby(['id'])[col].apply(norm_entropy)\n",
    "            df[col + '_SRAV'] = data.groupby(['id'])[col].apply(SRAV)\n",
    "            df[col + '_kurtosis'] = data.groupby(['id'])[col].apply(_kurtosis) \n",
    "            df[col + '_zero_crossing'] = data.groupby(['id'])[col].apply(zero_crossing) \n",
    "\n",
    "    return df    \n",
    "\n",
    "\n",
    "# Criando novas features atraces do PCA / ICA / GRP e SRP\n",
    "def cluster_fe(data):\n",
    "    \n",
    "    n_comp = 4\n",
    "\n",
    "    # tSVD\n",
    "    tsvd = TruncatedSVD(n_components=n_comp, random_state=42)\n",
    "    tsvd_results_df = tsvd.fit_transform(data[['item_id','dept_id','cat_id','store_id','state_id','wm_yr_wk','wday','month','year','event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI','sell_price','id']])\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_comp, random_state=42)\n",
    "    pca2_results_df = pca.fit_transform(data[['item_id','dept_id','cat_id','store_id','state_id','wm_yr_wk','wday','month','year','event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI','sell_price','id']])\n",
    "\n",
    "    # ICA\n",
    "    ica = FastICA(n_components=n_comp, random_state=42)\n",
    "    ica2_results_df = ica.fit_transform(data[['item_id','dept_id','cat_id','store_id','state_id','wm_yr_wk','wday','month','year','event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI','sell_price','id']])\n",
    "\n",
    "    # GRP\n",
    "    grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=42)\n",
    "    grp_results_df = grp.fit_transform(data[['item_id','dept_id','cat_id','store_id','state_id','wm_yr_wk','wday','month','year','event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI','sell_price','id']])\n",
    "\n",
    "    # SRP\n",
    "    srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=42)\n",
    "    srp_results_df = srp.fit_transform(data[['item_id','dept_id','cat_id','store_id','state_id','wm_yr_wk','wday','month','year','event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI','sell_price','id']])\n",
    "\n",
    "\n",
    "    # Append dos componentes com o dataset\n",
    "    for i in range(1, n_comp+1):\n",
    "        data['pca_demand'  + str(i)]  = pca2_results_df[:,i-1]\n",
    "        data['ica_demand'  + str(i)]  = ica2_results_df[:,i-1]\n",
    "        data['tsvd_demand' + str(i)]  = tsvd_results_df[:,i-1]\n",
    "        data['grp_demand'  + str(i)]  = grp_results_df[:,i-1]\n",
    "        data['srp_demand'  + str(i)]  = srp_results_df[:,i-1] \n",
    "        \n",
    "    return data      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(853720, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.38281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.97070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14390</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.97070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.64062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14410</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.88086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id  demand  source  \\\n",
       "0  14370     1437        3       1         0         0       0       2   \n",
       "1  14380     1438        3       1         0         0       0       2   \n",
       "2  14390     1439        3       1         0         0       0       2   \n",
       "3  14400     1440        3       1         0         0       0       2   \n",
       "4  14410     1441        3       1         0         0       0       2   \n",
       "\n",
       "         date  wm_yr_wk  wday  month  year  event_name_1  event_type_1  \\\n",
       "0  2016-04-25     11613     3      4     6            -1            -1   \n",
       "1  2016-04-25     11613     3      4     6            -1            -1   \n",
       "2  2016-04-25     11613     3      4     6            -1            -1   \n",
       "3  2016-04-25     11613     3      4     6            -1            -1   \n",
       "4  2016-04-25     11613     3      4     6            -1            -1   \n",
       "\n",
       "   event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \n",
       "0            -1            -1        0        0        0     8.38281  \n",
       "1            -1            -1        0        0        0     3.97070  \n",
       "2            -1            -1        0        0        0     2.97070  \n",
       "3            -1            -1        0        0        0     4.64062  \n",
       "4            -1            -1        0        0        0     2.88086  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('input/test_v3.pkl')\n",
    "print(train.shape); train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(853720, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>totalSnow_cm</th>\n",
       "      <th>FeelsLikeC</th>\n",
       "      <th>HeatIndexC</th>\n",
       "      <th>WindChillC</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>tempC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.38281</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>11.70312</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>31.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.70312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.97070</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>11.70312</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>31.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.70312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14390</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.97070</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>11.70312</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>31.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.70312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.64062</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>11.70312</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>31.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.70312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14410</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.88086</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>11.70312</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>31.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.70312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id  demand  source  \\\n",
       "0  14370     1437        3       1         0         0       0       2   \n",
       "1  14380     1438        3       1         0         0       0       2   \n",
       "2  14390     1439        3       1         0         0       0       2   \n",
       "3  14400     1440        3       1         0         0       0       2   \n",
       "4  14410     1441        3       1         0         0       0       2   \n",
       "\n",
       "         date  wm_yr_wk  wday  month  year  event_name_1  event_type_1  \\\n",
       "0  2016-04-25     11613     3      4     6            -1            -1   \n",
       "1  2016-04-25     11613     3      4     6            -1            -1   \n",
       "2  2016-04-25     11613     3      4     6            -1            -1   \n",
       "3  2016-04-25     11613     3      4     6            -1            -1   \n",
       "4  2016-04-25     11613     3      4     6            -1            -1   \n",
       "\n",
       "   event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \\\n",
       "0            -1            -1        0        0        0     8.38281   \n",
       "1            -1            -1        0        0        0     3.97070   \n",
       "2            -1            -1        0        0        0     2.97070   \n",
       "3            -1            -1        0        0        0     4.64062   \n",
       "4            -1            -1        0        0        0     2.88086   \n",
       "\n",
       "   totalSnow_cm  FeelsLikeC  HeatIndexC  WindChillC  humidity  precipMM  \\\n",
       "0       0.00000     8.10156    11.70312     8.10156  31.50000   0.00000   \n",
       "1       0.00000     8.10156    11.70312     8.10156  31.50000   0.00000   \n",
       "2       0.00000     8.10156    11.70312     8.10156  31.50000   0.00000   \n",
       "3       0.00000     8.10156    11.70312     8.10156  31.50000   0.00000   \n",
       "4       0.00000     8.10156    11.70312     8.10156  31.50000   0.00000   \n",
       "\n",
       "     tempC  \n",
       "0 11.70312  \n",
       "1 11.70312  \n",
       "2 11.70312  \n",
       "3 11.70312  \n",
       "4 11.70312  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = add_weather(train, weather)\n",
    "print(train.shape); train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Chamando as funcoes de criacao de novas features de agrupamento\n",
    "train = cluster_fe(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Chamando as funcoes de criacao de novas features\n",
    "train = simple_fe(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sell_price'] = train['sell_price'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "#train = reduce_mem_usage(train)\n",
    "# Chamando as funcoes de criacao de novas features estatisticas avancadas\n",
    "adv_fe = advanced_fe(train)\n",
    "adv_fe.reset_index(drop=False, inplace=False)\n",
    "\n",
    "# Realizando o merge final\n",
    "df_merge = pd.merge(train, adv_fe, on='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
